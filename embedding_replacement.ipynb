{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "embedding_replacement.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9830498f14d64353a871e6a609f41aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4f4f418cf5f4141afdcd9d3e4a46292",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29313d6cf8874574aff883bc7003e5ad",
              "IPY_MODEL_9b9d82d906bd4187afb4297ce74efff7"
            ]
          }
        },
        "c4f4f418cf5f4141afdcd9d3e4a46292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29313d6cf8874574aff883bc7003e5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_882ca16b8baf4325b3794ca0660bd1e1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_daba07304fc04c02a6d41f3888deb8bd"
          }
        },
        "9b9d82d906bd4187afb4297ce74efff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_29ab021428674311a4ec7a2dbd0c4a56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:10&lt;00:00, 40.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc723beddff74368a41e0d30ad3a7ec0"
          }
        },
        "882ca16b8baf4325b3794ca0660bd1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "daba07304fc04c02a6d41f3888deb8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29ab021428674311a4ec7a2dbd0c4a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc723beddff74368a41e0d30ad3a7ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa91c22395484a95b73898cd9a34e7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4015b69ba10a4ca1aef8f7e20ee7a697",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c02b5963c02a4ceb89ead60b99c6d561",
              "IPY_MODEL_5be15ee7b760417490c4b03782710ebf"
            ]
          }
        },
        "4015b69ba10a4ca1aef8f7e20ee7a697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c02b5963c02a4ceb89ead60b99c6d561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76beac02a7674b6abeca9c0074a79c96",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d663d0d7d6bf4b968ec4977fc6c13d77"
          }
        },
        "5be15ee7b760417490c4b03782710ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5700608c9d4c40e19c7a03700efb76da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:08&lt;00:00, 51.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ae999d3db9746178d6a485cea50eb5c"
          }
        },
        "76beac02a7674b6abeca9c0074a79c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d663d0d7d6bf4b968ec4977fc6c13d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5700608c9d4c40e19c7a03700efb76da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ae999d3db9746178d6a485cea50eb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10ImvVGtAaXg"
      },
      "source": [
        "Replacement of GLOVE embeddings with BERT embedding.\r\n",
        "\r\n",
        "We will be experimenting with a batch of 64 samples from SQuAD 2.0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITbuMi488tHu"
      },
      "source": [
        "# !pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "# import torch\n",
        "# print(torch.__version__)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTNk_EmTvzPA"
      },
      "source": [
        "import torch \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw0plWkCBfQ4"
      },
      "source": [
        "Cloning Huggingface repo.\r\n",
        "Huggingface transformers has a significant number of pending issues. We clone a tested version of Huggingface transformers for all our experiments. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBdZQ2zmrZoi",
        "outputId": "c85fe2a1-474f-4960-9d05-b547237f47be"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers \\\r\n",
        "&& cd transformers \\\r\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xuC2HSUrcgi"
      },
      "source": [
        "!pip install ./transformers\r\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Ic8Hts24Nh"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "\n",
        "import numpy as np\n",
        "import torch \n",
        "from transformers import BertModel"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFEzafJwB_Hb"
      },
      "source": [
        "The file 'word2idx.json' is a file that contains all the GLOVE indices of every word in the vocabulary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAyIiVvLseI-"
      },
      "source": [
        "import json  \n",
        "f = open('/content/word2idx.json',) \n",
        "data = json.load(f)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYHO_XZXskeZ"
      },
      "source": [
        "idx2word = {}\n",
        "for key in data.keys():\n",
        "    idx2word[data[key]] = key"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66cygqAPK_ji"
      },
      "source": [
        "Tensor ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kym2EE_ACO83"
      },
      "source": [
        "Tensors obtained from the pre-processing steps of the baseline BiDAF from Stanford. \r\n",
        "These tensors will now be transformed into equivalent BERT embeddings.\r\n",
        "\r\n",
        "cw_idxs - pickle file that contains all the contexts tokenized using the GLOVE tokenizer.\r\n",
        "qw_idxs - pickle file that contains all the questions tokenized using the GLOVE tokenizer.\r\n",
        "\r\n",
        "y1 is a vector with answer start indices and y2 for answer end indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP8Ax_IOEwDq"
      },
      "source": [
        "# Context file for one batch\n",
        "import pickle\n",
        "with open('cw_idxs.pickle', 'rb') as handle:\n",
        "    cw_idxs = pickle.load(handle)\n",
        "\n",
        "# Question file for one batch\n",
        "with open('qw_idxs.pickle', 'rb') as handle:\n",
        "    qw_idxs = pickle.load(handle)\n",
        "\n",
        "# Answer starts\n",
        "with open('y1.pickle', 'rb') as handle:\n",
        "    y1 = pickle.load(handle)\n",
        "\n",
        "# Answer ends\n",
        "with open('y2.pickle', 'rb') as handle:\n",
        "    y2 = pickle.load(handle)  "
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jdEcRX7C4nJ"
      },
      "source": [
        "shapes of pre-processed tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT89E46yE-4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec555f43-ea9b-4625-dc04-6a7a873b3258"
      },
      "source": [
        "print(cw_idxs.shape)\n",
        "print(qw_idxs.shape)\n",
        "print(y1.shape)\n",
        "print(y2.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 376])\n",
            "torch.Size([64, 23])\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiTIMirsC82i"
      },
      "source": [
        "Out of 64 samples, use a small batch of 16 samples for quick testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN-AIzZDaeET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1277c3a4-755b-41fc-cefb-7a8de9eaf7db"
      },
      "source": [
        "b = 16\n",
        "cw_idxs = cw_idxs[:b]\n",
        "qw_idxs = qw_idxs[:b]\n",
        "y1 = y1[:b]\n",
        "y2 = y2[:b]\n",
        "\n",
        "print(cw_idxs.shape)\n",
        "print(qw_idxs.shape)\n",
        "print(y1.shape)\n",
        "print(y2.shape)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 376])\n",
            "torch.Size([16, 23])\n",
            "torch.Size([16])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp_tnordLTew"
      },
      "source": [
        "The function 'swap_tokens' performs a reverse of tokenization process to generate the contexts. Once the original sentences are obtained BERT tokenizer is used to tokenize these sentences. The tokenizer used by BERT is a word piece tokenizer. All BERT embeddings are converted to the same length by padding. \r\n",
        "This function returns a tuple of 3 values. The first one is tokenized version of context sentences, tokenized using BERT's tokenizer. The second one is a mask with binary values that can be used to seperate the padding and actual token information. The third one is list of word pieces. \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JgKpVZuWp4y"
      },
      "source": [
        "# NEW SWAP_TOKENS FUNCTION\n",
        "def swap_tokens(cw_idxs):\n",
        "    cw_idxs_words = []\n",
        "    for c in cw_idxs:\n",
        "        new_list = []\n",
        "        for i in c:\n",
        "            new_list.append(idx2word[i.item()])\n",
        "        cw_idxs_words.append(new_list) \n",
        "\n",
        "    sentences = []\n",
        "    for l in cw_idxs_words:\n",
        "        sent = []\n",
        "        for i in l:\n",
        "            if i=='--OOV--' or i =='--NULL--':\n",
        "                continue\n",
        "            else:\n",
        "                sent.append(i)\n",
        "\n",
        "        sent = ' '.join(sent)   \n",
        "        sentences.append(sent)\n",
        "\n",
        "    sentences_tokenized = []\n",
        "\n",
        "    bert_words = []\n",
        "    for s in sentences:\n",
        "        tt = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(s))\n",
        "        bert_words.append(tokenizer.convert_ids_to_tokens(tt))\n",
        "        tt = torch.Tensor(tt).type(torch.LongTensor)\n",
        "        sentences_tokenized.append(tt)\n",
        "\n",
        "    max_len = 0\n",
        "    for s in sentences_tokenized:\n",
        "        max_len = max(len(s),max_len)\n",
        "\n",
        "    sentences_tokenized_tensors = [] \n",
        "    for s in sentences_tokenized:\n",
        "        tt = torch.nn.ConstantPad1d((0, max_len - s.shape[0]), 0)(s)\n",
        "        sentences_tokenized_tensors.append(tt)\n",
        "\n",
        "    CT_new = torch.Tensor([])\n",
        "\n",
        "    for l in sentences_tokenized_tensors:\n",
        "        l = l.reshape((1,l.shape[0]))\n",
        "        CT_new = torch.cat((CT_new, l), 0)   \n",
        "\n",
        "    c_mask = torch.zeros_like(CT_new) != CT_new \n",
        "\n",
        "    return (CT_new, c_mask, bert_words)    "
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2mgA7B0FdOQ"
      },
      "source": [
        " A major problem that we facedduring the implementation of this portion of the project was performing suitable tokenization pre-possessing.  GLOVE uses a word based tokenizer to convert words to numbers whereas BERT usesa WordPiece tokenizer.  A word word piece tokenizer assigns a token to the different snippets ofa word.  For example the word ’calligraphy’ gets split into three tokens, ’call’, ’##ig’, ’##raphy’.A snippet with ’##’ symbol get attached to the snippet before it.\r\n",
        "\r\n",
        "The function 'collect_hash_words' is used to collect the indices of the words that are split by the word piece tokenizer. The output is a list of lists. Each inner list contains the indices for words that were split in that sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuDJsouldOd4"
      },
      "source": [
        "def collect_hash_words(bert_words):\n",
        "    import more_itertools as mit\n",
        "    hash_words_list = []\n",
        "\n",
        "    for sample in range(len(bert_words)):\n",
        "        test_mask = []\n",
        "        for i in range(len(bert_words[sample])):\n",
        "            if '#' in bert_words[sample][i]:\n",
        "                test_mask.append(1)\n",
        "            else:\n",
        "                test_mask.append(0)\n",
        "\n",
        "        ones = []\n",
        "        for i in range(len(test_mask)):\n",
        "            if test_mask[i]==1:\n",
        "                ones.append(i)\n",
        "\n",
        "        start_ones = []\n",
        "        for i in ones:\n",
        "            start_ones.append(i-1)\n",
        "        full_ones = sorted(list(set(sorted(start_ones + ones))))\n",
        "\n",
        "        ll = [list(group) for group in mit.consecutive_groups(full_ones)] \n",
        "        hash_words_list.append(ll)\n",
        "\n",
        "    return hash_words_list"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEM29OcIXeod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129570ba-21cd-4d37-dc84-a86bfdb66d57"
      },
      "source": [
        "context, context_m, bert_words_C = swap_tokens(cw_idxs)\n",
        "print(context.shape)\n",
        "print(context_m.shape)\n",
        "print(len(bert_words_C))\n",
        "print(len(bert_words_C[0]))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 388])\n",
            "torch.Size([16, 388])\n",
            "16\n",
            "388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHn_wdwFEsdr",
        "outputId": "0d581cd8-1c0b-41db-ec7a-7447cc0f4efc"
      },
      "source": [
        "print(bert_words_C[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['In', 'the', 'China', 'of', 'the', 'Yuan', ',', 'or', 'Mongol', 'era', ',', 'various', 'important', 'developments', 'in', 'the', 'arts', 'occurred', 'or', 'continued', 'in', 'their', 'development', ',', 'including', 'the', 'areas', 'of', 'painting', ',', 'mathematics', ',', 'call', '##ig', '##raphy', ',', 'poetry', ',', 'and', 'theater', ',', 'with', 'many', 'great', 'artists', 'and', 'writers', 'being', 'famous', 'today', '.', 'Due', 'to', 'the', 'coming', 'together', 'of', 'painting', ',', 'poetry', ',', 'and', 'call', '##ig', '##raphy', 'at', 'this', 'time', 'many', 'of', 'the', 'artists', 'practicing', 'these', 'different', 'pursuits', 'were', 'the', 'same', 'individuals', ',', 'though', 'perhaps', 'more', 'famed', 'for', 'one', 'area', 'of', 'their', 'achievements', 'than', 'others', '.', 'Often', 'in', 'terms', 'of', 'the', 'further', 'development', 'of', 'landscape', 'painting', 'as', 'well', 'as', 'the', 'classical', 'joining', 'together', 'of', 'the', 'arts', 'of', 'painting', ',', 'poetry', ',', 'and', 'call', '##ig', '##raphy', ',', 'the', 'Song', 'dynasty', 'and', 'the', 'Yuan', 'dynasty', 'are', 'linked', 'together', '.', 'In', 'the', 'area', 'of', 'Chinese', 'painting', 'during', 'the', 'Yuan', 'dynasty', 'there', 'were', 'many', 'famous', 'painters', '.', 'In', 'the', 'area', 'of', 'call', '##ig', '##raphy', 'many', 'of', 'the', 'great', 'call', '##ig', '##rap', '##hers', 'were', 'from', 'the', 'Yuan', 'dynasty', 'era', '.', 'In', 'Yuan', 'poetry', ',', 'the', 'main', 'development', 'was', 'the', 'q', '##u', ',', 'which', 'was', 'used', 'among', 'other', 'poetic', 'forms', 'by', 'most', 'of', 'the', 'famous', 'Yuan', 'poets', '.', 'Many', 'of', 'the', 'poets', 'were', 'also', 'involved', 'in', 'the', 'major', 'developments', 'in', 'the', 'theater', 'during', 'this', 'time', ',', 'and', 'the', 'other', 'way', 'around', ',', 'with', 'people', 'important', 'in', 'the', 'theater', 'becoming', 'famous', 'through', 'the', 'development', 'of', 'the', 'type', 'of', 'q', '##u', '.', 'One', 'of', 'the', 'key', 'factors', 'in', 'the', 'mix', 'of', 'the', 'variety', 'show', 'was', 'the', 'incorporation', 'of', 'poetry', 'both', 'classical', 'and', 'of', 'the', 'newer', 'q', '##u', 'form', '.', 'One', 'of', 'the', 'important', 'cultural', 'developments', 'during', 'the', 'Yuan', 'era', 'was', 'the', 'consolidation', 'of', 'poetry', ',', 'painting', ',', 'and', 'call', '##ig', '##raphy', 'into', 'a', 'unified', 'piece', 'of', 'the', 'type', 'that', 'tends', 'to', 'come', 'to', 'mind', 'when', 'people', 'think', 'of', 'classical', 'Chinese', 'art', '.', 'Another', 'important', 'aspect', 'of', 'Yuan', 'times', 'is', 'the', 'increasing', 'incorporation', 'of', 'the', 'then', 'current', ',', 'vernacular', 'Chinese', 'into', 'both', 'the', 'q', '##u', 'form', 'of', 'poetry', 'and', 'the', 'variety', 'show', '.', 'Another', 'important', 'consideration', 'regarding', 'Yuan', 'dynasty', 'arts', 'and', 'culture', 'is', 'that', 'so', 'much', 'of', 'it', 'has', 'survived', 'in', 'China', ',', 'relatively', 'to', 'works', 'from', 'the', 'Tang', 'dynasty', 'and', 'Song', 'dynasty', ',', 'which', 'have', 'often', 'been', 'better', 'preserved', 'in', 'places', 'such', 'as', 'the', ',', 'in', 'Japan', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUBj4jMHXoJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d713e61e-b1c6-493c-f753-abc6b356d7ec"
      },
      "source": [
        "question, question_m, bert_words_Q = swap_tokens(qw_idxs)\n",
        "print(question.shape)\n",
        "print(question_m.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 25])\n",
            "torch.Size([16, 25])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_6bX5gqeGcR",
        "outputId": "7fda6155-673b-4f9c-a486-0f9432d6f1fe"
      },
      "source": [
        "hash_words_list_C =  collect_hash_words(bert_words_C)\n",
        "hash_words_list_Q =  collect_hash_words(bert_words_Q)\n",
        "print(len(hash_words_list_C))\n",
        "print(len(hash_words_list_Q))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZelq3Z9GPF8"
      },
      "source": [
        "Identifying words with a hash-connection (Ex:'call', '##ig', '##raphy')\r\n",
        "\r\n",
        "Each list in 'hash_words_list_C' is a list of words that need to be combined. Words such as 'call', '##ig', '##raphy'\r\n",
        "We take an average of the embeddings of each of these components(call', '##ig', '##raphy') and return the final embedding for the word 'calligraphy'. Every context and question has a variable number of such words. \r\n",
        "\r\n",
        "Out of a batch of 16 context paragraphs, the example below shows that there 10 words that were split by the word piece tokenizer. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtheuidXFEuw",
        "outputId": "3fa79b95-ab4d-437c-e775-8caf39f171c7"
      },
      "source": [
        "hash_words_list_C[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32, 33, 34],\n",
              " [62, 63, 64],\n",
              " [120, 121, 122],\n",
              " [155, 156, 157],\n",
              " [162, 163, 164, 165],\n",
              " [182, 183],\n",
              " [239, 240],\n",
              " [265, 266],\n",
              " [288, 289, 290],\n",
              " [332, 333]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "68iLad8eFw3f",
        "outputId": "337aba7d-f9a2-4080-b079-2d876dbc8532"
      },
      "source": [
        "context.type()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nstWjNIK3nB"
      },
      "source": [
        "# Converting float tensot to long tensor\n",
        "context = torch.Tensor(context).type(torch.LongTensor)\n",
        "question = torch.Tensor(question).type(torch.LongTensor)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZA8WXlOF35u",
        "outputId": "47a2b05f-dd08-4afc-be08-eebe2579e24a"
      },
      "source": [
        "#  16 context paragraphs, each paragraph is of size 388. \r\n",
        "context.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 388])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWkbssZGGAUd",
        "outputId": "878a8159-6d54-4023-9d5c-5ed72293f4ea"
      },
      "source": [
        "# Output of bert tokenization, for the first 20 words\r\n",
        "context[0][:20]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1130,  1103,  1975,  1104,  1103, 13049,   117,  1137, 18739,  3386,\n",
              "          117,  1672,  1696,  9093,  1107,  1103,  3959,  3296,  1137,  1598])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hurfq6lwGyXq"
      },
      "source": [
        "Now that we have our tokenized context we can use the BERT model to generate embeddings for all the context sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK6xk4JfMp5m"
      },
      "source": [
        "# model_name_or_path = 'bert-base-uncased'\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "hidden_size = 100\n",
        "\n",
        "class Bert_Embeddings(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Bert_Embeddings, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    last_hidden_state ,_ = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    output = last_hidden_state\n",
        "    return output"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqZZP6wDMpo-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "9830498f14d64353a871e6a609f41aac",
            "c4f4f418cf5f4141afdcd9d3e4a46292",
            "29313d6cf8874574aff883bc7003e5ad",
            "9b9d82d906bd4187afb4297ce74efff7",
            "882ca16b8baf4325b3794ca0660bd1e1",
            "daba07304fc04c02a6d41f3888deb8bd",
            "29ab021428674311a4ec7a2dbd0c4a56",
            "dc723beddff74368a41e0d30ad3a7ec0",
            "aa91c22395484a95b73898cd9a34e7f6",
            "4015b69ba10a4ca1aef8f7e20ee7a697",
            "c02b5963c02a4ceb89ead60b99c6d561",
            "5be15ee7b760417490c4b03782710ebf",
            "76beac02a7674b6abeca9c0074a79c96",
            "d663d0d7d6bf4b968ec4977fc6c13d77",
            "5700608c9d4c40e19c7a03700efb76da",
            "7ae999d3db9746178d6a485cea50eb5c"
          ]
        },
        "outputId": "1789eac3-9a5d-4933-e1a5-d89d27eb5dde"
      },
      "source": [
        "model = Bert_Embeddings(hidden_size)\n",
        "with torch.no_grad():\n",
        "    c_hs = model(input_ids=context[:b].reshape((b,context.shape[1])), \n",
        "                attention_mask=context_m[:b].reshape((b,context.shape[1])))\n",
        "\n",
        "    q_hs = model(input_ids=question[:b].reshape((b,question.shape[1])), \n",
        "                attention_mask=question_m[:b].reshape((b,question.shape[1])))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9830498f14d64353a871e6a609f41aac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa91c22395484a95b73898cd9a34e7f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lD6jcS2MpEb",
        "outputId": "b7f6c4c1-2b08-47e2-e837-4ded238b592c"
      },
      "source": [
        "c_hs.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([388, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x694o2DeA-Zs"
      },
      "source": [
        "q_hs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPaJKdjBJ59F"
      },
      "source": [
        "Once the embeddings are generated, use the output from 'collect_hash_words' function to find which words have been split by BERT's tokenizer. For every word that is split compute the average of the it's word snippets and form a single embedding for the word. This carried out using the 'remove function'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UToTl6YrlmR7"
      },
      "source": [
        "def remove_hash(f, hash_words_list, hs):\r\n",
        "    sub = []\r\n",
        "    for l in hash_words_list[f]:\r\n",
        "        arr = []\r\n",
        "        for i in l:\r\n",
        "            c = hs[f][i].detach().numpy()\r\n",
        "            arr.append(c)\r\n",
        "\r\n",
        "        arr = np.array(arr)\r\n",
        "        arr = np.mean(arr, axis=0)\r\n",
        "        sub.append((arr, l[0]))\r\n",
        "\r\n",
        "    # sub --> [([],__),  ([],__),  ([],__)....]    \r\n",
        "\r\n",
        "    #  Replace all means\r\n",
        "    for s,i in sub:\r\n",
        "        hs[f][i] = torch.Tensor(s)     \r\n",
        "\r\n",
        "    # Remove unnecessary values\r\n",
        "    remove = []\r\n",
        "    for l in hash_words_list[f]:\r\n",
        "        remove.append(l[1:])\r\n",
        "    flat_list = [item for sublist in remove for item in sublist]  \r\n",
        "\r\n",
        "\r\n",
        "    hs_new = torch.Tensor([])\r\n",
        "    for i in range(len(hs[f])):\r\n",
        "        if i in flat_list:\r\n",
        "            continue\r\n",
        "        else:    \r\n",
        "            p = hs[f][i].reshape((1,-1))\r\n",
        "            hs_new = torch.cat((hs_new, p), 0)\r\n",
        "\r\n",
        "    return hs_new, flat_list        "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TwrQaGLkuC8"
      },
      "source": [
        "all_mods = []\r\n",
        "all_falt_lists_C = []\r\n",
        "\r\n",
        "for i in range(16):\r\n",
        "    hs_new, flat_list = remove_hash(i, hash_words_list_C, c_hs)\r\n",
        "    all_falt_lists_C.append(flat_list)\r\n",
        "    all_mods.append(hs_new)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1T-l-OfK-hM"
      },
      "source": [
        "Once the embeddings for the word snippets are replaced by a single embedding, we need to pad the embeddings ince again to get a Tensor with uniform size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B283wFQ-kt90",
        "outputId": "60764b15-a299-4c27-f837-a5dd42171cc9"
      },
      "source": [
        "for l in all_mods:\r\n",
        "    print(l.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([371, 768])\n",
            "torch.Size([361, 768])\n",
            "torch.Size([379, 768])\n",
            "torch.Size([372, 768])\n",
            "torch.Size([381, 768])\n",
            "torch.Size([365, 768])\n",
            "torch.Size([381, 768])\n",
            "torch.Size([381, 768])\n",
            "torch.Size([379, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([355, 768])\n",
            "torch.Size([352, 768])\n",
            "torch.Size([383, 768])\n",
            "torch.Size([379, 768])\n",
            "torch.Size([381, 768])\n",
            "torch.Size([368, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYaU3XVslNEM",
        "outputId": "0a7d0b80-8b51-4ff9-d22e-04dc8d4692b9"
      },
      "source": [
        "max_len = 0\r\n",
        "for a in all_mods:\r\n",
        "    max_len = max(max_len, a.shape[0])\r\n",
        "print(max_len)      "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-xBIozhrQTz"
      },
      "source": [
        "all_mods_tensors = [] \r\n",
        "for s in all_mods:\r\n",
        "    tt = torch.transpose(torch.nn.ConstantPad2d((0, max_len - s.shape[0]), 0)(torch.transpose(s, 0, 1)), 0, 1)\r\n",
        "    all_mods_tensors.append(tt)  "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqmK3rCXLRS8"
      },
      "source": [
        "Successful padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tW-6phBrQOJ",
        "outputId": "6ef25a59-89f4-48d0-b6cd-b332823dcacd"
      },
      "source": [
        "for l in all_mods_tensors:\r\n",
        "    print(l.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n",
            "torch.Size([384, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kixUO6L6yR3-"
      },
      "source": [
        "rect_c_hs = torch.Tensor([])\r\n",
        "\r\n",
        "for l in all_mods_tensors:\r\n",
        "    l = l.reshape((1,l.shape[0], l.shape[1]))\r\n",
        "    rect_c_hs = torch.cat((rect_c_hs, l), 0)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V1TaOfPLi1f"
      },
      "source": [
        "Final BERT embedding that is ready to be fed into the BiDAF network.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgKPJaM4yRzv",
        "outputId": "b1a4b75d-b0b6-4160-a409-4ec12921904f"
      },
      "source": [
        "print(rect_c_hs.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 384, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LijLba5KL2KM"
      },
      "source": [
        "Perform the same steps for questions Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5_WGLh1zgyI",
        "outputId": "59f140b2-f0aa-43c9-f80d-31dd35f479f6"
      },
      "source": [
        "# Similarly for questions\r\n",
        "all_mods = []\r\n",
        "all_falt_lists_Q = []\r\n",
        "\r\n",
        "for i in range(16):\r\n",
        "    hs_new, flat_list = remove_hash(i, hash_words_list_Q, q_hs)\r\n",
        "    all_falt_lists_Q.append(flat_list)\r\n",
        "    all_mods.append(hs_new)\r\n",
        "\r\n",
        "max_len = 0\r\n",
        "for a in all_mods:\r\n",
        "    max_len = max(max_len, a.shape[0])   \r\n",
        "\r\n",
        "all_mods_tensors = [] \r\n",
        "for s in all_mods:\r\n",
        "    tt = torch.transpose(torch.nn.ConstantPad2d((0, max_len - s.shape[0]), 0)(torch.transpose(s, 0, 1)), 0, 1)\r\n",
        "    all_mods_tensors.append(tt)      \r\n",
        "\r\n",
        "rect_q_hs = torch.Tensor([])\r\n",
        "\r\n",
        "for l in all_mods_tensors:\r\n",
        "    l = l.reshape((1,l.shape[0], l.shape[1]))\r\n",
        "    rect_q_hs = torch.cat((rect_q_hs, l), 0)    \r\n",
        "\r\n",
        "print(rect_q_hs.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 25, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEzAb1B6L8OL"
      },
      "source": [
        "Our BiDAF model needs a mask that can be used to indentify the actual embeddings and padding embeddings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4FCcpuz3OlR",
        "outputId": "a13ce226-63bf-4c3d-e45f-20a1943f5771"
      },
      "source": [
        "context.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 388])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xuFNqHG3v8h",
        "outputId": "44194c30-f4b9-445d-e50b-c2d3b499353a"
      },
      "source": [
        "context_m.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 388])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPv30H-i2xOx",
        "outputId": "3d3bdd5c-21e1-4bee-cb74-6a1f64aa9357"
      },
      "source": [
        "context[1]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1650, 27241,  1103, 20164,  7222, 12512,  1116,  1127,  1113,  1103,\n",
              "         5341,   117,  1105,  1103,  1433,  5672,  3666,  2997,   119,   138,\n",
              "         1326,  1104,  1210,  1353,  2987,  8755,  1227,  1112,  1103, 20164,\n",
              "         7222, 12512,  8833,  1116,  2795,  1149,   117,  2871,  1107, 10231,\n",
              "         1699,   117,  1206, 19163,  1475,  1105, 19163,  1580,   119, 11733,\n",
              "         1174,  1222,  4276,  3748,   119,  1109, 13034,  3296,   170,  4967,\n",
              "         1378,  1103,  1473,  1104,  1985,  4191,   117,   170, 20164,  7222,\n",
              "        12512,  1196, 17821,  1106, 17164,   117,  1150,  1125,  4921, 21516,\n",
              "         1194,  1103,  5316, 17882,  1104, 20689,  3052,   119,  1230,  5714,\n",
              "         2535, 16214,   117,  1223,  1103,  1231,  4915,  3457,  1104,  1117,\n",
              "         2169,  2336,  1534,  4238,  1260,   112, 25650,   117,  1245,  1167,\n",
              "         1154,  2879,  2861,  1104,  7999,  1863,   119,  1109, 20164,  7222,\n",
              "        12512,  1116,  6297,  1118,  7046,  2457,  1741,  1105,  1764,  4413,\n",
              "          117,  7046,  8311, 10492,  1114,  2880,  3758,   117,  1105,  9990,\n",
              "        11733,  1158,  1222,  2129,  1540,   119,  1109,  8833,  1116,  1127,\n",
              "        24034,  1742,  2599,  4999, 14336,  1118,  1103,  1497,  1834,   166,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3rsrYIZz7Es",
        "outputId": "ed564a77-1c88-4eb5-f755-1d330257e181"
      },
      "source": [
        "context_m[1]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iBoqFVSQO5y",
        "outputId": "f67133d1-6465-4c89-a603-ef74833ac41e"
      },
      "source": [
        "for l in all_falt_lists_C:\r\n",
        "    print(l)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[33, 34, 63, 64, 121, 122, 156, 157, 163, 164, 165, 183, 240, 266, 289, 290, 333]\n",
            "[4, 5, 6, 30, 31, 32, 33, 44, 47, 50, 69, 70, 83, 86, 96, 97, 111, 112, 115, 119, 120, 121, 141, 148, 151, 152, 153]\n",
            "[19, 33, 36, 40, 46, 72, 122, 128, 131]\n",
            "[21, 34, 35, 36, 56, 57, 66, 69, 70, 71, 75, 96, 97, 109, 110, 111]\n",
            "[1, 2, 3, 53, 73, 112, 153]\n",
            "[7, 8, 15, 16, 60, 68, 69, 77, 82, 89, 90, 91, 113, 129, 132, 141, 174, 175, 176, 184, 185, 189, 190]\n",
            "[55, 66, 84, 85, 108, 109, 110]\n",
            "[8, 18, 19, 30, 75, 80, 96]\n",
            "[31, 32, 59, 96, 103, 104, 176, 209, 210]\n",
            "[3, 18, 92, 101]\n",
            "[5, 8, 14, 47, 58, 59, 66, 67, 81, 82, 88, 89, 107, 108, 111, 130, 139, 140, 141, 149, 152, 155, 156, 157, 182, 183, 198, 199, 200, 204, 224, 225, 226]\n",
            "[10, 11, 12, 28, 29, 30, 37, 40, 41, 59, 63, 64, 65, 75, 76, 104, 105, 106, 107, 108, 118, 119, 139, 148, 149, 168, 169, 170, 177, 196, 197, 198, 202, 203, 214, 258]\n",
            "[30, 36, 47, 80, 95]\n",
            "[31, 32, 59, 96, 103, 104, 176, 209, 210]\n",
            "[52, 53, 54, 55, 75, 107, 136]\n",
            "[9, 10, 24, 29, 30, 40, 41, 50, 59, 60, 74, 75, 80, 83, 88, 89, 94, 113, 121, 122]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE6mMKHIR9aH",
        "outputId": "b8b24793-b7e3-469f-d5f3-ba6cb344918a"
      },
      "source": [
        "context_m.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 388])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivZQfsXpJC86",
        "outputId": "0a7886b6-8a3b-4a50-d487-863324ad3eb5"
      },
      "source": [
        "context_np = context.numpy()\r\n",
        "context_np.shape"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 388)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW9rGbNHO5tX"
      },
      "source": [
        "all_mod_mask_C = []\r\n",
        "for i in range(len(context_np)):\r\n",
        "    arr = []\r\n",
        "    for j in range(len(context_np[i])):\r\n",
        "        if j in all_falt_lists_C[i]:\r\n",
        "            continue\r\n",
        "        else:\r\n",
        "            arr.append(context_np[i][j])\r\n",
        "\r\n",
        "    for z in range(len(all_falt_lists_C[i])):\r\n",
        "        arr.append(0)\r\n",
        "    all_mod_mask_C.append(arr)                "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPgM4bLDTNmb",
        "outputId": "71bff2b7-5f8a-4524-af26-c39043a45f73"
      },
      "source": [
        "for l in all_mod_mask_C:\r\n",
        "    print(len(l))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1130, 1103, 1975, 1104, 1103, 13049, 117, 1137, 18739, 3386, 117, 1672, 1696, 9093, 1107, 1103, 3959, 3296, 1137, 1598, 1107, 1147, 1718, 117, 1259, 1103, 1877, 1104, 3504, 117, 6686, 117, 1840, 117, 4678, 117, 1105, 5184, 117, 1114, 1242, 1632, 2719, 1105, 5094, 1217, 2505, 2052, 119, 4187, 1106, 1103, 1909, 1487, 1104, 3504, 117, 4678, 117, 1105, 1840, 1120, 1142, 1159, 1242, 1104, 1103, 2719, 13029, 1292, 1472, 27305, 1127, 1103, 1269, 2833, 117, 1463, 3229, 1167, 16916, 1111, 1141, 1298, 1104, 1147, 10227, 1190, 1639, 119, 12812, 1107, 2538, 1104, 1103, 1748, 1718, 1104, 5882, 3504, 1112, 1218, 1112, 1103, 4521, 4577, 1487, 1104, 1103, 3959, 1104, 3504, 117, 4678, 117, 1105, 1840, 117, 1103, 3765, 6107, 1105, 1103, 13049, 6107, 1132, 5128, 1487, 119, 1130, 1103, 1298, 1104, 1922, 3504, 1219, 1103, 13049, 6107, 1175, 1127, 1242, 2505, 15233, 119, 1130, 1103, 1298, 1104, 1840, 1242, 1104, 1103, 1632, 1840, 1127, 1121, 1103, 13049, 6107, 3386, 119, 1130, 13049, 4678, 117, 1103, 1514, 1718, 1108, 1103, 186, 117, 1134, 1108, 1215, 1621, 1168, 15751, 2769, 1118, 1211, 1104, 1103, 2505, 13049, 11587, 119, 2408, 1104, 1103, 11587, 1127, 1145, 2017, 1107, 1103, 1558, 9093, 1107, 1103, 5184, 1219, 1142, 1159, 117, 1105, 1103, 1168, 1236, 1213, 117, 1114, 1234, 1696, 1107, 1103, 5184, 2479, 2505, 1194, 1103, 1718, 1104, 1103, 2076, 1104, 186, 119, 1448, 1104, 1103, 2501, 5320, 1107, 1103, 5495, 1104, 1103, 2783, 1437, 1108, 1103, 19542, 1104, 4678, 1241, 4521, 1105, 1104, 1103, 11483, 186, 1532, 119, 1448, 1104, 1103, 1696, 3057, 9093, 1219, 1103, 13049, 3386, 1108, 1103, 20994, 1104, 4678, 117, 3504, 117, 1105, 1840, 1154, 170, 13943, 2727, 1104, 1103, 2076, 1115, 12246, 1106, 1435, 1106, 1713, 1165, 1234, 1341, 1104, 4521, 1922, 1893, 119, 2543, 1696, 7631, 1104, 13049, 1551, 1110, 1103, 4138, 19542, 1104, 1103, 1173, 1954, 117, 21662, 1922, 1154, 1241, 1103, 186, 1532, 1104, 4678, 1105, 1103, 2783, 1437, 119, 2543, 1696, 9486, 4423, 13049, 6107, 3959, 1105, 2754, 1110, 1115, 1177, 1277, 1104, 1122, 1144, 4399, 1107, 1975, 117, 3860, 1106, 1759, 1121, 1103, 10215, 6107, 1105, 3765, 6107, 117, 1134, 1138, 1510, 1151, 1618, 6018, 1107, 2844, 1216, 1112, 1103, 117, 1107, 1999, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1650, 27241, 1103, 20164, 1127, 1113, 1103, 5341, 117, 1105, 1103, 1433, 5672, 3666, 2997, 119, 138, 1326, 1104, 1210, 1353, 2987, 8755, 1227, 1112, 1103, 20164, 2795, 1149, 117, 2871, 1107, 10231, 1699, 117, 1206, 19163, 1105, 19163, 119, 11733, 1222, 4276, 3748, 119, 1109, 13034, 3296, 170, 4967, 1378, 1103, 1473, 1104, 1985, 4191, 117, 170, 20164, 1196, 17821, 1106, 17164, 117, 1150, 1125, 4921, 21516, 1194, 1103, 5316, 1104, 20689, 119, 1230, 5714, 2535, 16214, 117, 1223, 1103, 1231, 1104, 1117, 2169, 2336, 1534, 4238, 1260, 112, 25650, 117, 1245, 1167, 1154, 1104, 7999, 119, 1109, 20164, 6297, 1118, 7046, 2457, 1741, 1105, 1764, 4413, 117, 7046, 8311, 10492, 1114, 2880, 3758, 117, 1105, 9990, 11733, 1222, 2129, 1540, 119, 1109, 8833, 1127, 24034, 14336, 1118, 1103, 1497, 1834, 166, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[7092, 1103, 4186, 1432, 117, 25738, 4133, 1104, 1103, 1540, 1104, 2255, 1105, 1714, 1209, 1245, 6506, 1621, 26544, 9813, 117, 4518, 1343, 9813, 1105, 1147, 19215, 1107, 6646, 1114, 1167, 2361, 117, 11110, 1332, 1103, 9800, 2986, 1104, 25992, 1681, 22515, 1452, 1107, 12838, 1105, 1103, 2084, 1104, 5051, 2419, 20816, 1452, 170, 1214, 1224, 117, 1107, 13419, 117, 170, 5637, 2795, 1149, 1166, 1147, 5627, 119, 1985, 22846, 1108, 1809, 1106, 1103, 2643, 1107, 13403, 117, 1105, 1103, 7691, 4424, 21630, 1108, 1923, 1106, 1103, 11223, 1104, 5051, 1160, 1201, 1224, 117, 1134, 24771, 1103, 4787, 1104, 1103, 12600, 1121, 1103, 14678, 1104, 2361, 4133, 1120, 5051, 1106, 1103, 14678, 1104, 7691, 117, 24446, 4133, 113, 3393, 1118, 2361, 1112, 6115, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1109, 2012, 2049, 1178, 4096, 2626, 1852, 7876, 9150, 119, 1438, 117, 170, 25399, 1104, 1103, 2049, 1110, 4379, 1206, 1125, 113, 1103, 1436, 1227, 1859, 1217, 1103, 2049, 1115, 4096, 1206, 183, 1107, 12861, 27349, 114, 1112, 1103, 4272, 2049, 119, 3446, 1103, 2012, 2049, 4096, 18814, 117, 12086, 1112, 176, 117, 1134, 1532, 1226, 1104, 1103, 8496, 185, 1105, 187, 117, 1134, 4521, 21994, 1103, 4272, 2049, 113, 1267, 1142, 8366, 1111, 1167, 114, 119, 1109, 4290, 1104, 1242, 18806, 1111, 1714, 186, 1144, 2602, 1115, 1103, 7876, 9150, 4634, 1132, 1136, 2626, 184, 119, 1188, 9501, 1110, 1270, 2942, 24478, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[3177, 117, 1122, 1108, 1103, 1211, 7188, 1331, 1107, 2870, 117, 1114, 2418, 2849, 1104, 2880, 118, 1255, 4131, 119, 1130, 1901, 1106, 1103, 3129, 2656, 117, 1175, 1108, 170, 2418, 2778, 7309, 1107, 7760, 119, 1792, 1106, 1938, 2314, 1104, 5678, 117, 1149, 1104, 1103, 1703, 1416, 1104, 5519, 117, 1288, 117, 4384, 12810, 22588, 117, 1288, 113, 1213, 3236, 110, 3029, 114, 119, 7760, 112, 188, 3073, 2778, 1416, 1104, 1167, 1190, 8301, 117, 1288, 12810, 1164, 1476, 3029, 1104, 1103, 1331, 112, 188, 1703, 1416, 119, 1130, 3698, 117, 1149, 1104, 4131, 1127, 1104, 3129, 1534, 3661, 119, 1291, 1414, 1563, 2014, 1103, 17898, 1104, 1103, 1331, 117, 1105, 1106, 1142, 1285, 1175, 1110, 1277, 1750, 5237, 9531, 1190, 1107, 1103, 2166, 3127, 1201, 1104, 7760, 112, 188, 1607, 119, 2082, 1104, 1103, 2030, 1285, 1416, 3213, 1110, 1359, 1113, 4422, 10348, 1105, 3953, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[8328, 4220, 1110, 2533, 1107, 1103, 12477, 5189, 1133, 1145, 1120, 1103, 171, 2725, 1105, 15542, 119, 1109, 1211, 2418, 2275, 1132, 1457, 119, 1287, 112, 188, 5761, 113, 5740, 1432, 114, 117, 1103, 3550, 1110, 170, 4701, 1859, 1104, 1103, 1177, 118, 1270, 26506, 25213, 1947, 117, 1457, 119, 2090, 112, 188, 1722, 113, 16308, 114, 117, 170, 1411, 1402, 1104, 139, 1266, 113, 5740, 1432, 114, 117, 11274, 5646, 113, 1170, 15679, 114, 1105, 1103, 1787, 3856, 140, 113, 114, 119, 1109, 1211, 3385, 5136, 1104, 8236, 4220, 1107, 1103, 1331, 1132, 1103, 1402, 1104, 6800, 1266, 113, 17801, 114, 117, 1459, 1270, 107, 1109, 13898, 107, 113, 1346, 4815, 1432, 114, 1105, 1995, 113, 19207, 114, 119, 1109, 1211, 5426, 5136, 1104, 4758, 4220, 1132, 1103, 1787, 3856, 113, 114, 1105, 1103, 14335, 1722, 113, 114, 1120, 2476, 2779, 119, 3841, 1103, 1148, 4413, 1104, 1103, 1346, 26194, 1103, 1211, 1696, 1132, 1457, 119, 145, 112, 188, 1722, 113, 114, 1105, 14159, 112, 188, 9518, 113, 26180, 114, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1735, 1913, 1644, 1110, 3666, 1118, 1103, 5333, 1104, 1420, 2231, 1105, 1103, 2031, 1104, 3302, 1104, 1103, 1735, 1913, 119, 2777, 1103, 3892, 1104, 1420, 2231, 2194, 1111, 9774, 2266, 1735, 1913, 1644, 1169, 1129, 17538, 1118, 1103, 5333, 1104, 1420, 2231, 119, 1130, 1692, 1104, 1735, 1913, 1644, 1134, 1431, 1138, 1151, 14715, 1154, 1103, 3892, 1104, 1420, 2231, 117, 1216, 1112, 15974, 117, 1103, 1735, 2827, 1169, 1321, 10830, 1222, 1103, 1420, 1352, 1223, 1103, 6599, 1113, 1103, 16068, 1104, 1103, 1735, 1913, 119, 1109, 1735, 2031, 1104, 3302, 1110, 1103, 2439, 2175, 1682, 1106, 19348, 1735, 1913, 1644, 119, 15463, 3509, 1104, 1735, 1913, 1644, 1511, 1692, 1644, 1118, 1103, 2031, 1104, 3302, 117, 1835, 1644, 1105, 1704, 6551, 1104, 1735, 1913, 1644, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[25308, 1107, 19068, 13450, 1127, 1189, 1118, 13919, 1219, 1103, 13049, 3386, 119, 1109, 13919, 16920, 14104, 113, 114, 13785, 19648, 11838, 1114, 1146, 1106, 1300, 3655, 1606, 170, 10848, 9245, 1104, 23795, 117, 4976, 1106, 2030, 24350, 119, 16920, 1215, 170, 3442, 1104, 10466, 1106, 4851, 1103, 19648, 11838, 1106, 170, 1423, 8381, 1114, 1178, 1141, 3655, 119, 1230, 3442, 1110, 1758, 1107, 1103, 14976, 13861, 1104, 1103, 3396, 16285, 117, 1637, 1107, 7029, 119, 1109, 2280, 5097, 4651, 170, 18217, 1104, 19636, 112, 188, 12099, 119, 1109, 7584, 1104, 170, 10996, 24205, 1326, 1110, 1145, 2262, 1107, 1103, 1520, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1507, 1103, 1752, 21572, 118, 1983, 1414, 1107, 5901, 117, 1999, 8761, 6036, 119, 1249, 170, 1871, 1104, 1103, 18182, 118, 1983, 1414, 1107, 4761, 117, 1999, 1261, 1226, 1104, 17784, 2054, 1121, 2733, 119, 3577, 1108, 13706, 1107, 4178, 119, 1507, 1291, 1414, 146, 117, 1999, 1261, 1528, 118, 12222, 6835, 1107, 1975, 787, 188, 20642, 2715, 117, 1112, 1218, 1112, 1103, 24764, 117, 7515, 117, 1105, 5137, 3503, 119, 1130, 3428, 117, 1999, 3749, 2192, 1104, 1677, 2638, 2733, 1105, 2192, 1104, 2638, 17991, 1112, 170, 14031, 1107, 1103, 24196, 11300, 119, 1130, 3916, 1999, 11578, 2268, 1121, 1975, 119, 1507, 1103, 2307, 21572, 118, 1983, 1414, 1107, 3493, 117, 1999, 112, 188, 1764, 10784, 2129, 1975, 1105, 1118, 1103, 1322, 1104, 1103, 2662, 1414, 117, 1999, 1125, 11578, 1277, 1104, 1103, 8040, 1689, 117, 1259, 3475, 3462, 117, 4357, 117, 13101, 117, 12820, 117, 1103, 4336, 117, 5572, 117, 1226, 1104, 1203, 6793, 1105, 1199, 5011, 1104, 1103, 2662, 4879, 119, 1999, 1145, 10784, 5872, 117, 3181, 1103, 1583, 1154, 170, 6888, 120, 1983, 7214, 119, 2098, 5929, 21681, 1127, 2207, 1118, 1103, 2681, 1104, 1103, 1244, 1311, 1107, 1103, 2307, 1291, 1414, 1105, 1103, 1378, 19151, 1134, 1231, 1343, 6835, 1106, 1237, 3469, 1137, 1147, 1560, 5032, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[6364, 1114, 19024, 1107, 4909, 117, 1980, 1145, 1598, 1106, 4657, 1107, 1764, 2815, 119, 1735, 17382, 1189, 10310, 16454, 1115, 1180, 1129, 1215, 1107, 4127, 117, 1105, 1114, 18168, 1107, 11360, 1152, 1127, 1682, 1106, 10032, 4725, 16025, 119, 1650, 1103, 12931, 117, 1103, 3395, 2560, 1125, 1561, 1126, 3903, 13777, 4621, 119, 1188, 2815, 1522, 1735, 9099, 1126, 4316, 1166, 1147, 7741, 117, 1112, 9099, 1107, 1750, 118, 1872, 2182, 1127, 1253, 2935, 1114, 15130, 117, 12604, 117, 1105, 5439, 18254, 113, 174, 119, 176, 119, 1103, 163, 1107, 2685, 2201, 1219, 1103, 7342, 118, 163, 1414, 1104, 6917, 114, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[2485, 1103, 10627, 1104, 25938, 1107, 8347, 117, 1103, 1393, 6550, 12786, 6107, 1127, 1923, 1112, 17620, 118, 1704, 117, 3037, 1112, 7749, 3878, 1118, 1103, 13049, 117, 12590, 117, 1105, 13838, 118, 3386, 6670, 117, 17841, 1107, 1103, 3199, 1104, 23967, 119, 25911, 1111, 1103, 13049, 6107, 117, 1649, 117, 1108, 1126, 1107, 2463, 117, 1224, 3989, 1277, 188, 1105, 4422, 5637, 119, 1188, 5338, 1112, 1346, 1112, 1103, 1322, 1104, 23209, 112, 188, 5436, 119, 23209, 2034, 1417, 1117, 6921, 1488, 117, 117, 1112, 1103, 5373, 2558, 117, 1133, 1119, 1452, 1196, 23209, 1107, 11965, 119, 4516, 117, 112, 188, 1503, 1488, 117, 1114, 1103, 1619, 1104, 1117, 1534, 1105, 1103, 3907, 2410, 117, 3760, 1103, 5774, 1105, 4741, 1112, 12008, 4340, 117, 1137, 3637, 117, 1121, 14949, 1106, 7029, 119, 12008, 4340, 1879, 1106, 4731, 1105, 2760, 1277, 1104, 1103, 1250, 4972, 1118, 1117, 5112, 119, 1124, 1145, 1189, 3519, 1114, 1103, 2466, 18739, 180, 1112, 1218, 1112, 8480, 2182, 1216, 1112, 4357, 117, 1134, 3037, 1117, 16251, 28117, 1105, 3004, 7529, 1111, 170, 1374, 4397, 119, 1438, 117, 1103, 8065, 1107, 1103, 13049, 6107, 1310, 1219, 1103, 5436, 1104, 12008, 4340, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1130, 8911, 117, 1103, 2379, 1607, 9548, 1104, 2535, 138, 1127, 10214, 1241, 1107, 1203, 1365, 1105, 1113, 1103, 3314, 1120, 5051, 1531, 119, 138, 112, 188, 3136, 1108, 21389, 7891, 1105, 185, 4038, 112, 107, 6251, 1107, 1103, 13434, 7009, 107, 1105, 1103, 5417, 1104, 4287, 107, 8066, 3796, 107, 119, 138, 112, 188, 7281, 1113, 2598, 3490, 8310, 1114, 1107, 1105, 1103, 13457, 1115, 170, 1825, 1169, 10598, 1103, 107, 10455, 2197, 107, 1107, 1155, 14343, 119, 1332, 1122, 1338, 1106, 10100, 1297, 118, 2769, 117, 138, 1106, 5218, 1104, 3571, 1359, 1113, 170, 15504, 9072, 1111, 1117, 2554, 119, 1188, 7058, 2458, 1104, 3044, 1108, 1107, 3838, 1114, 1103, 12815, 1104, 6869, 26456, 5230, 4408, 1121, 3250, 20692, 1819, 8721, 1105, 12786, 5272, 117, 2133, 1759, 1127, 1226, 1104, 1103, 5051, 9403, 1120, 1103, 1159, 119, 1109, 5587, 1104, 138, 112, 188, 3268, 1106, 107, 1177, 1114, 21137, 107, 1930, 1145, 4408, 1121, 1168, 7961, 1106, 1134, 5051, 1651, 1127, 5490, 117, 1259, 21137, 1118, 6197, 140, 117, 1287, 117, 1107, 170, 20359, 13585, 117, 4424, 4922, 119, 1109, 3340, 3002, 1120, 5051, 7063, 1115, 1103, 7961, 1104, 21137, 1105, 1117, 1346, 2030, 1105, 20359, 8618, 1127, 1593, 1112, 4857, 2373, 1219, 1103, 2835, 1432, 1112, 1343, 1104, 1103, 107, 2078, 5027, 107, 1104, 1103, 1167, 20607, 1105, 1167, 21357, 3250, 1278, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[15144, 4540, 1169, 1129, 1163, 1106, 1138, 1151, 1103, 2232, 2049, 1481, 1103, 7080, 4543, 1105, 1486, 6506, 2595, 1329, 3759, 11360, 1107, 11615, 117, 11467, 1105, 7785, 132, 1540, 15486, 2930, 132, 1105, 21146, 3936, 26498, 1216, 1112, 2529, 7499, 117, 2968, 117, 5543, 1105, 1812, 4011, 119, 2397, 1329, 1107, 6487, 1521, 1106, 1126, 2773, 1107, 1103, 1657, 1907, 1111, 13958, 119, 1247, 1138, 1120, 1141, 1159, 1137, 1330, 1151, 5543, 118, 5605, 3922, 20224, 117, 21552, 113, 1443, 1277, 2244, 114, 1105, 1256, 23338, 1112, 1103, 5481, 15144, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1507, 1103, 1752, 21572, 118, 1983, 1414, 1107, 5901, 117, 1999, 8761, 6036, 119, 1249, 170, 1871, 1104, 1103, 18182, 118, 1983, 1414, 1107, 4761, 117, 1999, 1261, 1226, 1104, 17784, 2054, 1121, 2733, 119, 3577, 1108, 13706, 1107, 4178, 119, 1507, 1291, 1414, 146, 117, 1999, 1261, 1528, 118, 12222, 6835, 1107, 1975, 787, 188, 20642, 2715, 117, 1112, 1218, 1112, 1103, 24764, 117, 7515, 117, 1105, 5137, 3503, 119, 1130, 3428, 117, 1999, 3749, 2192, 1104, 1677, 2638, 2733, 1105, 2192, 1104, 2638, 17991, 1112, 170, 14031, 1107, 1103, 24196, 11300, 119, 1130, 3916, 1999, 11578, 2268, 1121, 1975, 119, 1507, 1103, 2307, 21572, 118, 1983, 1414, 1107, 3493, 117, 1999, 112, 188, 1764, 10784, 2129, 1975, 1105, 1118, 1103, 1322, 1104, 1103, 2662, 1414, 117, 1999, 1125, 11578, 1277, 1104, 1103, 8040, 1689, 117, 1259, 3475, 3462, 117, 4357, 117, 13101, 117, 12820, 117, 1103, 4336, 117, 5572, 117, 1226, 1104, 1203, 6793, 1105, 1199, 5011, 1104, 1103, 2662, 4879, 119, 1999, 1145, 10784, 5872, 117, 3181, 1103, 1583, 1154, 170, 6888, 120, 1983, 7214, 119, 2098, 5929, 21681, 1127, 2207, 1118, 1103, 2681, 1104, 1103, 1244, 1311, 1107, 1103, 2307, 1291, 1414, 1105, 1103, 1378, 19151, 1134, 1231, 1343, 6835, 1106, 1237, 3469, 1137, 1147, 1560, 5032, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1418, 7056, 25346, 1103, 1497, 1406, 1106, 122, 1114, 170, 1416, 1104, 1164, 122, 119, 126, 1550, 16859, 1373, 1103, 2638, 3153, 1104, 1103, 10995, 117, 1121, 6584, 9418, 1105, 12033, 1107, 1103, 1564, 117, 1106, 3260, 1107, 1103, 1588, 119, 2408, 1104, 1103, 2214, 8990, 1125, 1657, 3711, 1115, 2925, 170, 1677, 1106, 1103, 1745, 117, 1112, 1103, 6102, 1104, 1103, 10995, 1108, 3655, 1120, 1103, 1159, 1147, 5586, 7394, 1127, 3609, 119, 1799, 1147, 1416, 6425, 1127, 1373, 1103, 3153, 117, 1103, 7536, 1127, 2898, 1154, 1103, 4604, 119, 6584, 9418, 117, 1134, 1125, 1151, 3297, 1121, 1699, 1107, 19619, 117, 1253, 1125, 170, 2418, 1497, 118, 3522, 1416, 119, 2855, 1145, 2694, 15288, 112, 188, 4026, 117, 1187, 1103, 6236, 112, 188, 2410, 1881, 6537, 1111, 9015, 1114, 1469, 6872, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[2408, 1227, 12133, 3553, 1132, 6321, 1106, 1129, 25731, 117, 1133, 1142, 1144, 1136, 1151, 4132, 119, 1370, 5374, 153, 866, 151, 866, 27660, 866, 12727, 117, 1133, 1122, 1110, 1936, 1115, 153, 134, 12727, 119, 1409, 153, 1110, 1136, 4463, 1106, 151, 117, 1173, 153, 1110, 1136, 4463, 1106, 12727, 1719, 119, 1967, 1175, 1132, 1242, 1227, 12133, 3553, 1206, 153, 1105, 12727, 117, 1216, 1112, 155, 117, 21062, 117, 27660, 117, 139, 117, 9960, 117, 153, 117, 3576, 119, 117, 1122, 1110, 1936, 1115, 1155, 1292, 12133, 3553, 7546, 1106, 1141, 1705, 119, 5096, 1115, 1251, 1104, 1292, 3553, 1132, 25731, 1156, 1129, 170, 1558, 15036, 1107, 12133, 2749, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSjHg6nfNP5S"
      },
      "source": [
        "all_mod_mask_C_pt = []\r\n",
        "\r\n",
        "for l in all_mod_mask_C:\r\n",
        "    all_mod_mask_C_pt.append(torch.Tensor(l))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZS0ng4BNPwb",
        "outputId": "93c69e49-46cf-4c9f-f30e-897394fcf573"
      },
      "source": [
        "context_new = torch.Tensor([])\r\n",
        "\r\n",
        "for l in all_mod_mask_C_pt:\r\n",
        "    l = l.reshape((1,l.shape[0]))\r\n",
        "    context_new = torch.cat((context_new, l), 0)\r\n",
        "\r\n",
        "print(context_new.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 388])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4q1r-3x9oVk"
      },
      "source": [
        "context_new[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOlcvBGLRgPY",
        "outputId": "19940a30-297e-4753-a80a-e7a8162f1bbc"
      },
      "source": [
        "c_mask_new = torch.zeros_like(context_new) != context_new \r\n",
        "print(c_mask_new.shape)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 388])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkTpI_8DRf9D",
        "outputId": "f04406cf-997d-46e9-ab28-fc6cbccab8da"
      },
      "source": [
        "# Similarly generate a new mask for questions\r\n",
        "\r\n",
        "question_np = question.numpy()\r\n",
        "question_np.shape\r\n",
        "\r\n",
        "all_mod_mask_Q = []\r\n",
        "for i in range(len(question_np)):\r\n",
        "    arr = []\r\n",
        "    for j in range(len(question_np[i])):\r\n",
        "        if j in all_falt_lists_Q[i]:\r\n",
        "            continue\r\n",
        "        else:\r\n",
        "            arr.append(question_np[i][j])\r\n",
        "\r\n",
        "    for z in range(len(all_falt_lists_Q[i])):\r\n",
        "        arr.append(0)\r\n",
        "    all_mod_mask_Q.append(arr) \r\n",
        "\r\n",
        "\r\n",
        "all_mod_mask_Q_pt = []\r\n",
        "for l in all_mod_mask_Q:\r\n",
        "    all_mod_mask_Q_pt.append(torch.Tensor(l))   \r\n",
        "\r\n",
        "\r\n",
        "question_new = torch.Tensor([])\r\n",
        "for l in all_mod_mask_Q_pt:\r\n",
        "    l = l.reshape((1,l.shape[0]))\r\n",
        "    question_new = torch.cat((question_new, l), 0)\r\n",
        "print(question_new.shape)   \r\n",
        "\r\n",
        "q_mask_new = torch.zeros_like(question_new) != question_new \r\n",
        "print(q_mask_new.shape)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 25])\n",
            "torch.Size([16, 25])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7daGdehaA4IS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}