{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Project 2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqUnwcMUsN4A"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('dev-v2.0.json') as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "with open('train-v2.0.json') as f:\n",
        "  train_data = json.load(f)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAswO1_U56HD",
        "outputId": "a7b9b749-c30d-48df-bc71-07d75b02638d"
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize import word_tokenize  \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet \n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzu0wpEhUCSd"
      },
      "source": [
        "Structure of the data is as follows. \n",
        "The training dataset is a dictionary which has 2 key-value pairs.\n",
        "1. 'version': v2.0\n",
        "2. 'data': list of 442 elements where each element is another dictionary containing,\n",
        "*   'title': Single word describing the paragraphs. (Ex. 'IPod')\n",
        "*   'paragraphs': List of elements where each element is another dictionary containing,\n",
        "1. 'context': Context paragraph from which the model needs to highlight answer to each question if possible and return not available if it is unanswerable.\n",
        "2. 'qas': List of elements where each element is another dictionary containing,\n",
        "*   'id': Unique ID through which the answers are compared while evaluating our model.\n",
        "*   'is_impossible': Boolean value which describes whether the answer can be found in the context or not.\n",
        "*   'question': Question string.\n",
        "*   'answers': List of elements where each element is another dictionary containing,\n",
        "1. 'answer_start': The character number of the answer in the context.\n",
        "2. 'text': The answer string from context paragraph.\n",
        "*  Generally there is only one answer to every question so a question arises why a list of dictionary and why not just dictionary? The reason we think is in dev-set, the structure is exactly the same except 'answers' where it contains upto 5 dictionaries (crowdsourced) and our model is awarded points if it matches any of those answers.\n",
        "*  If is_impossible is True, then 'answers' will be an empty string and there will be another key called 'plausible_answers' whose structure is same as 'answers'.\n",
        "\n",
        "*  We will go through the structure of dataset taking an example.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrWMw0-UXVi4",
        "outputId": "982e5ae4-7780-4ecf-b696-57597b7f7425"
      },
      "source": [
        "train_data.keys()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['version', 'data'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ur3c2jpsbAJE",
        "outputId": "240e072d-b18f-41e6-8cea-5e30699b2551"
      },
      "source": [
        "train_data['version']"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'v2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMUk8HnUbCj2",
        "outputId": "4c28cf12-c621-477b-9ca9-b9947a5740e1"
      },
      "source": [
        "# There are a total of 442 title, paragraphs tuples.\n",
        "type(train_data['data']), len(train_data['data'])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, 442)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O797NDwJbCnJ",
        "outputId": "a69b3ffe-95b9-4c7c-daa8-be457a9458d8"
      },
      "source": [
        "train_data['data'][3].keys()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['title', 'paragraphs'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ch-yc3A5bCqK",
        "outputId": "7a1d0281-4363-43c3-aee9-22ddb69d79b4"
      },
      "source": [
        "train_data['data'][3]['title']"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IPod'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBriwOi3bCtb",
        "outputId": "946f44df-91f3-48fb-ddf8-739a8c91d313"
      },
      "source": [
        "# For this example, there are 60 context paragraphs. We will publish the detail statistics of number of paragraphs under each title later in the notebook.\n",
        "len(train_data['data'][3]['paragraphs'])"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ_zvVksbCwd",
        "outputId": "0189fa23-8602-4b49-f62d-a6b5385c35b5"
      },
      "source": [
        "train_data['data'][3]['paragraphs'][0].keys()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['qas', 'context'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "461geg7bbCz3",
        "outputId": "3d242e59-1934-45a6-e737-6a8324a9276c"
      },
      "source": [
        "train_data['data'][3]['paragraphs'][0]['context']"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The iPod is a line of portable media players and multi-purpose pocket computers designed and marketed by Apple Inc. The first line was released on October 23, 2001, about 8½ months after iTunes (Macintosh version) was released. The most recent iPod redesigns were announced on July 15, 2015. There are three current versions of the iPod: the ultra-compact iPod Shuffle, the compact iPod Nano and the touchscreen iPod Touch.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpTncI9sbC3K",
        "outputId": "091ff41f-5003-43d9-ff05-f42010136009"
      },
      "source": [
        "# For this example, there are 10 question-answer pairs. We will publish the detail statistics of number of questions under each context later.\n",
        "len(train_data['data'][3]['paragraphs'][0]['qas'])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDC4kC6nbC6e",
        "outputId": "8aebd261-c857-43e3-9eb8-a5767161b10b"
      },
      "source": [
        "train_data['data'][3]['paragraphs'][0]['qas'][0].keys()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['question', 'id', 'answers', 'is_impossible'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6HnE0tYbC93",
        "outputId": "f28546e1-c6a5-4bc3-8ebe-c766c65b3e1e"
      },
      "source": [
        "train_data['data'][3]['paragraphs'][0]['qas'][0]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': [{'answer_start': 105, 'text': 'Apple'}],\n",
              " 'id': '56cc55856d243a140015ef0a',\n",
              " 'is_impossible': False,\n",
              " 'question': 'Which company produces the iPod?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t2_NEK5dAmt",
        "outputId": "6a0b3701-841a-4e2c-abcd-2ad2c35b4e2b"
      },
      "source": [
        "# If is_impossible is True, the 'answers' value will be empty and there will be a new key 'plausible_answers'\n",
        "train_data['data'][441]['paragraphs'][0]['qas'][0]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': [],\n",
              " 'id': '5a7db48670df9f001a87505f',\n",
              " 'is_impossible': True,\n",
              " 'plausible_answers': [{'answer_start': 50,\n",
              "   'text': 'ordinary matter composed of atoms'}],\n",
              " 'question': 'What did the term matter include after the 20th century?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkzgVVfOdG8R",
        "outputId": "1da9f97c-8de8-4272-d5ca-fdede3f52a7b"
      },
      "source": [
        "# This is an example of dev-set. The only difference is that it contains upto 5 answers (in this case 4 answers). If our output resembles any of these\n",
        "# answers, we get the points.\n",
        "data['data'][0]['paragraphs'][0]['qas'][4]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': [{'answer_start': 671, 'text': '10th century'},\n",
              "  {'answer_start': 649, 'text': 'the first half of the 10th century'},\n",
              "  {'answer_start': 671, 'text': '10th'},\n",
              "  {'answer_start': 671, 'text': '10th'}],\n",
              " 'id': '56ddde6b9a695914005b962c',\n",
              " 'is_impossible': False,\n",
              " 'question': 'What century did the Normans first gain their separate identity?'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhU3Sew-udzY"
      },
      "source": [
        "# Brief stats about the dataset.\n",
        "\n",
        "poss = 0\n",
        "imposs = 0\n",
        "all_para_cnt = []\n",
        "all_q_cnt = []\n",
        "for elems in train_data['data']:\n",
        "  para_cnt = 0\n",
        "  for paras_under_title in elems['paragraphs']:\n",
        "    para_cnt += 1\n",
        "    q_cnt = 0\n",
        "    for each_ques in paras_under_title['qas']:\n",
        "      q_cnt += 1\n",
        "      if each_ques['is_impossible'] == False:\n",
        "        poss += 1\n",
        "      else:\n",
        "        imposs += 1\n",
        "    all_q_cnt.append(q_cnt)\n",
        "  all_para_cnt.append(para_cnt)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH4s3hWzTPrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1eb8f3-68a9-4789-953c-d5d580da5df9"
      },
      "source": [
        "print(f'Total No. context paragraphs = {sum(all_para_cnt)}, Average No. of context paragraphs per title = {sum(all_para_cnt)/len(all_para_cnt)}')\n",
        "print(f'Total No. Questions = {sum(all_q_cnt)}, Average No. of Questions per context paragraph = {sum(all_q_cnt)/len(all_q_cnt)}')\n",
        "print(f'No. questions which have answers in the context paragraph = {poss}, which do not have answers in the context paragraph = {imposs}')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total No. context paragraphs = 19035, Average No. of context paragraphs per title = 43.06561085972851\n",
            "Total No. Questions = 130319, Average No. of Questions per context paragraph = 6.84628316259522\n",
            "No. questions which have answers in the context paragraph = 86821, which do not have answers in the context paragraph = 43498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2lVleghV_JQ"
      },
      "source": [
        "# Given a word, get_synonyms(word) returns a list of synonyms of this particular word. \n",
        "\n",
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    \n",
        "    for syn in wordnet.synsets(word): \n",
        "        for l in syn.lemmas(): \n",
        "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
        "            synonyms.add(synonym) \n",
        "    \n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    \n",
        "    return list(synonyms)\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import random\n",
        "all_chars = ' qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'\n",
        "# Goal is to replace some words in a context with their respective synonyms so that the meaning won't change and the performance will increase\n",
        "# if these modified context paragraphs are added to the original training dataset.\n",
        "# For every word in the context, with 0.2 probability we replace it with a synonym (if exists), with 0.8 probability, we leave it unchanged.\n",
        "# After tokenizing the context string into individual words and applying this algorithm, we need to untokenize it so that\n",
        "# a coherent passage string is formed. \n",
        "# To append these new data samples, we also need answers to each question corresponding to the contexts. \n",
        "# As we have seen in the data analysis phase, we need to modify 'answer_start' feature and 'text' feature to new values.\n",
        "# For example, if an answer in original context is 'happy moments', the answer in modified context may be 'joyful moments'.\n",
        "# Not only did the words change, but also the start character position has changed.\n",
        "# To retrieve new answer_starts, we first pass a list of old answer_starts, make a copy of it and sort it. \n",
        "# Keep a flag value which stores the change in length of the string till now. Say for example 'happy moments' has answer_start = 53 in old context\n",
        "# and 'joyful moments' has answer_start = 61 in new context. Logic to update flag is flag <-- flag + len(synonym) - len(old word). \n",
        "# Until 53 has reached, we keep adding to flag, and once it is reached we store it in a flag_list to be returned as output later.\n",
        "\n",
        "\n",
        "# Takes context paragraph and start indices of answers corresponding to a particular context's questions.\n",
        "# Outputs list of synonym words, flag list ()\n",
        "\n",
        "def modify_contexts(context, ans_start_list):\n",
        "  ans_start_list.sort()\n",
        "  flag = 0\n",
        "  word_tokens = word_tokenize(context)\n",
        "  output = []\n",
        "\n",
        "  # running_length will help us compare whether we have reached answer_start after iterating over each word.\n",
        "  running_length = 0\n",
        "  flag_list = [0 for i in range(len(ans_start_list))]\n",
        "  for word in word_tokens:\n",
        "\n",
        "    # This list is used to fetch p = 0.2\n",
        "    lstt = [0,1,1,1,1]\n",
        "\n",
        "    # If word contains anything other than alphabets, we don't find synonyms\n",
        "    if set(word).issubset(set(all_chars)):\n",
        "      # adding +1 as well to accompany spaces\n",
        "      running_length += len(word) + 1\n",
        "      # p = 0.2\n",
        "      if random.choice(lstt) == 0:\n",
        "        \n",
        "        # If word is a stop_word, we don't find synonym.\n",
        "        if word not in stop_words:\n",
        "          temp = get_synonyms(word)\n",
        "          if len(temp) == 0:\n",
        "            output.append(word)\n",
        "          else:\n",
        "            substitute = random.choice(temp)\n",
        "            for i in range(len(flag_list)):\n",
        "              if running_length < ans_start_list[i]:\n",
        "                # Logic to update flag\n",
        "                flag_list[i] += len(substitute) - len(word)\n",
        "            output.append(substitute)\n",
        "        else:\n",
        "          output.append(word)\n",
        "      else:\n",
        "        output.append(word)\n",
        "    else:\n",
        "      running_length += len(word)\n",
        "      output.append(word)\n",
        "\n",
        "  return output, flag_list\n",
        "\n",
        "# Input is a list of words and output is a string which contains all the words in a coherent manner (paragraph)\n",
        "import re\n",
        "def untokenize(words):\n",
        "    text = ' '.join(words)\n",
        "    step1 = text.replace(\"`` \", '\"').replace(\" ''\", '\"').replace('. . .',  '...')\n",
        "    step2 = step1.replace(\" ( \", \" (\").replace(\" ) \", \") \")\n",
        "    step3 = re.sub(r' ([.,:;?!%]+)([ \\'\"`])', r\"\\1\\2\", step2)\n",
        "    step4 = re.sub(r' ([.,:;?!%]+)$', r\"\\1\", step3)\n",
        "    step5 = step4.replace(\" '\", \"'\").replace(\" n't\", \"n't\").replace(\n",
        "         \"can not\", \"cannot\")\n",
        "    step6 = step5.replace(\" ` \", \" '\")\n",
        "    step7 = step6.replace(\" & \", \"&\")\n",
        "    step8 = step7.replace(\" [ \", \" [\").replace(\" ] \", \"] \")\n",
        "    return step8.strip()\n",
        "\n"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHRUpZrWYEru"
      },
      "source": [
        "# Takes an arr of numbers and flag_list as input and returns a flag_list which correspond to original ans_start_list sent into modify_context method\n",
        "# This helps us update the new 'answer_start' and 'text' easily\n",
        "\n",
        "def find_new_indices(arr, flag_list):\n",
        "  arr2 = arr.copy()\n",
        "  arr2.sort()\n",
        "  s = numpy.array(arr)\n",
        "  sort_index = numpy.argsort(s)\n",
        "  flag_list_return = flag_list.copy()\n",
        "  i = 0\n",
        "  for elem in sort_index:\n",
        "    flag_list_return[elem] = flag_list[i]\n",
        "    i += 1\n",
        "  return flag_list_return"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cObAfI-kQK0c"
      },
      "source": [
        "# Making another copy to be modified and to demonstrate how a paragraph and corresponding answers are changed.\n",
        "with open('train-v2.0.json') as f:\n",
        "  train_data2 = json.load(f)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jagYOnV48wtY"
      },
      "source": [
        "# Iterating and modifying the train_data to generate synonym contexts.\n",
        "\n",
        "import numpy\n",
        "for elems442 in train_data2['data']:\n",
        "  for paras_under_title in elems442['paragraphs']:\n",
        "    ans_start_arr = []\n",
        "    for each_ques in paras_under_title['qas']:\n",
        "      if not each_ques['is_impossible']:\n",
        "        # store answer_start for each question in ans_start_arr\n",
        "        ans_start_arr.append(each_ques['answers'][0]['answer_start'])\n",
        "        ans_start_arr.append(each_ques['answers'][0]['answer_start'] + len(each_ques['answers'][0]['text']))\n",
        "      else:\n",
        "        # store answer_start for each question in ans_start_arr\n",
        "        ans_start_arr.append(each_ques['plausible_answers'][0]['answer_start'])\n",
        "        ans_start_arr.append(each_ques['plausible_answers'][0]['answer_start'] + len(each_ques['plausible_answers'][0]['text']))\n",
        "\n",
        "    # store current context\n",
        "    temp_context = paras_under_title['context']\n",
        "\n",
        "    arr = ans_start_arr.copy()\n",
        "    # pass current context, list of answer_start into modify_contexts method.\n",
        "    ans, flag_list = modify_contexts(temp_context, arr)\n",
        "    # untokenize the list of words into single string\n",
        "    new_final_ans = untokenize(ans)\n",
        "\n",
        "    # \"UNSORT\" the flag values such that they correspong to the answer_start list sent into modify_contexts method\n",
        "    fl = find_new_indices(ans_start_arr, flag_list)\n",
        "    i = 0\n",
        "\n",
        "    # store new answers in a list\n",
        "    ans_texts = []\n",
        "    while i < len(ans_start_arr)-1:\n",
        "      ans_texts.append(new_final_ans[ans_start_arr[i] + fl[i]:ans_start_arr[i+1] + fl[i+1]])\n",
        "      i += 2\n",
        "    \n",
        "    i = 0\n",
        "    j = 0\n",
        "\n",
        "    # overwrite the answer text and answer_start in the dataset with new values\n",
        "\n",
        "    for each_ques in paras_under_title['qas']:\n",
        "      if each_ques['is_impossible'] == False:\n",
        "        each_ques['answers'][0]['answer_start'] = ans_start_arr[i] + fl[i]\n",
        "        each_ques['answers'][0]['text'] = ans_texts[j]\n",
        "      else:\n",
        "        each_ques['plausible_answers'][0]['answer_start'] = ans_start_arr[i] + fl[i]\n",
        "        each_ques['plausible_answers'][0]['text'] = ans_texts[j]\n",
        "      j += 1\n",
        "      i += 2\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NNGsw7sfrBy",
        "outputId": "831e8f57-6e9e-4b79-d4ce-20beba622d8c"
      },
      "source": [
        "# This is how an Question-Answers look like. Notice the change in answer_start and 'text'\n",
        "# For reference, we printed the original Quesion-Answers below\n",
        "train_data2['data'][0]['paragraphs'][0]['qas']"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answers': [{'answer_start': 268, 'text': 'in the late 1990s'}],\n",
              "  'id': '56be85543aeaaa14008c9063',\n",
              "  'is_impossible': False,\n",
              "  'question': 'When did Beyonce start becoming popular?'},\n",
              " {'answers': [{'answer_start': 204, 'text': 'singing and saltation'}],\n",
              "  'id': '56be85543aeaaa14008c9065',\n",
              "  'is_impossible': False,\n",
              "  'question': 'What areas did Beyonce compete in when she was growing up?'},\n",
              " {'answers': [{'answer_start': 534, 'text': '2003'}],\n",
              "  'id': '56be85543aeaaa14008c9066',\n",
              "  'is_impossible': False,\n",
              "  'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\"},\n",
              " {'answers': [{'answer_start': 166, 'text': 'Houston, tx'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9601',\n",
              "  'is_impossible': False,\n",
              "  'question': 'In what city and state did Beyonce  grow up? '},\n",
              " {'answers': [{'answer_start': 275, 'text': 'late 1990s'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9602',\n",
              "  'is_impossible': False,\n",
              "  'question': 'In which decade did Beyonce become famous?'},\n",
              " {'answers': [{'answer_start': 324, 'text': \"Destiny's baby\"}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9603',\n",
              "  'is_impossible': False,\n",
              "  'question': 'In what R&B group was she the lead singer?'},\n",
              " {'answers': [{'answer_start': 513, 'text': 'Dangerously in Love'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9604',\n",
              "  'is_impossible': False,\n",
              "  'question': 'What album made her a worldwide known artist?'},\n",
              " {'answers': [{'answer_start': 363, 'text': 'Mathew Knowles'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9605',\n",
              "  'is_impossible': False,\n",
              "  'question': \"Who managed the Destiny's Child group?\"},\n",
              " {'answers': [{'answer_start': 275, 'text': 'late 1990s'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830a9',\n",
              "  'is_impossible': False,\n",
              "  'question': 'When did Beyoncé rise to fame?'},\n",
              " {'answers': [{'answer_start': 289, 'text': 'lead singer of r'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830aa',\n",
              "  'is_impossible': False,\n",
              "  'question': \"What role did Beyoncé have in Destiny's Child?\"},\n",
              " {'answers': [{'answer_start': 513, 'text': 'Dangerously in Love'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830ab',\n",
              "  'is_impossible': False,\n",
              "  'question': 'What was the first album Beyoncé released as a solo artist?'},\n",
              " {'answers': [{'answer_start': 534, 'text': '2003'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830ac',\n",
              "  'is_impossible': False,\n",
              "  'question': 'When did Beyoncé release Dangerously in Love?'},\n",
              " {'answers': [{'answer_start': 599, 'text': 'five'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830ad',\n",
              "  'is_impossible': False,\n",
              "  'question': 'How many Grammy awards did Beyoncé win for her first solo album?'},\n",
              " {'answers': [{'answer_start': 289, 'text': 'lead singer of r'}],\n",
              "  'id': '56d43ce42ccc5a1400d830b4',\n",
              "  'is_impossible': False,\n",
              "  'question': \"What was Beyoncé's role in Destiny's Child?\"},\n",
              " {'answers': [{'answer_start': 513, 'text': 'Dangerously in Love'}],\n",
              "  'id': '56d43ce42ccc5a1400d830b5',\n",
              "  'is_impossible': False,\n",
              "  'question': \"What was the name of Beyoncé's first solo album?\"}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or8G2vIaYuCb",
        "outputId": "8be3ebab-2c39-4d76-b46a-a124d4332a0a"
      },
      "source": [
        "train_data['data'][0]['paragraphs'][0]['qas']"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'answers': [{'answer_start': 269, 'text': 'in the late 1990s'}],\n",
              "  'id': '56be85543aeaaa14008c9063',\n",
              "  'is_impossible': False,\n",
              "  'question': 'When did Beyonce start becoming popular?'},\n",
              " {'answers': [{'answer_start': 207, 'text': 'singing and dancing'}],\n",
              "  'id': '56be85543aeaaa14008c9065',\n",
              "  'is_impossible': False,\n",
              "  'question': 'What areas did Beyonce compete in when she was growing up?'},\n",
              " {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
              "  'id': '56be85543aeaaa14008c9066',\n",
              "  'is_impossible': False,\n",
              "  'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\"},\n",
              " {'answers': [{'answer_start': 166, 'text': 'Houston, Texas'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9601',\n",
              "  'is_impossible': False,\n",
              "  'question': 'In what city and state did Beyonce  grow up? '},\n",
              " {'answers': [{'answer_start': 276, 'text': 'late 1990s'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9602',\n",
              "  'is_impossible': False,\n",
              "  'question': 'In which decade did Beyonce become famous?'},\n",
              " {'answers': [{'answer_start': 320, 'text': \"Destiny's Child\"}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9603',\n",
              "  'is_impossible': False,\n",
              "  'question': 'In what R&B group was she the lead singer?'},\n",
              " {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9604',\n",
              "  'is_impossible': False,\n",
              "  'question': 'What album made her a worldwide known artist?'},\n",
              " {'answers': [{'answer_start': 360, 'text': 'Mathew Knowles'}],\n",
              "  'id': '56bf6b0f3aeaaa14008c9605',\n",
              "  'is_impossible': False,\n",
              "  'question': \"Who managed the Destiny's Child group?\"},\n",
              " {'answers': [{'answer_start': 276, 'text': 'late 1990s'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830a9',\n",
              "  'is_impossible': False,\n",
              "  'question': 'When did Beyoncé rise to fame?'},\n",
              " {'answers': [{'answer_start': 290, 'text': 'lead singer'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830aa',\n",
              "  'is_impossible': False,\n",
              "  'question': \"What role did Beyoncé have in Destiny's Child?\"},\n",
              " {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830ab',\n",
              "  'is_impossible': False,\n",
              "  'question': 'What was the first album Beyoncé released as a solo artist?'},\n",
              " {'answers': [{'answer_start': 526, 'text': '2003'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830ac',\n",
              "  'is_impossible': False,\n",
              "  'question': 'When did Beyoncé release Dangerously in Love?'},\n",
              " {'answers': [{'answer_start': 590, 'text': 'five'}],\n",
              "  'id': '56d43c5f2ccc5a1400d830ad',\n",
              "  'is_impossible': False,\n",
              "  'question': 'How many Grammy awards did Beyoncé win for her first solo album?'},\n",
              " {'answers': [{'answer_start': 290, 'text': 'lead singer'}],\n",
              "  'id': '56d43ce42ccc5a1400d830b4',\n",
              "  'is_impossible': False,\n",
              "  'question': \"What was Beyoncé's role in Destiny's Child?\"},\n",
              " {'answers': [{'answer_start': 505, 'text': 'Dangerously in Love'}],\n",
              "  'id': '56d43ce42ccc5a1400d830b5',\n",
              "  'is_impossible': False,\n",
              "  'question': \"What was the name of Beyoncé's first solo album?\"}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHmkXqo53Cxc"
      },
      "source": [
        "# Augmented data in this dictionary\n",
        "temp_dict = {}\n",
        "temp_dict['version'] = 'v2.0'\n",
        "temp_dict['data'] = []\n",
        "for i in range(len(train_data2['data'])):\n",
        "  temp_dict['data'].append(train_data2['data'][i].copy())"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oT0mt-A5wuS"
      },
      "source": [
        "# repliction-factor = 2\n",
        "for i in range(len(train_data2['data'])):\n",
        "  train_data['data'].append(train_data2['data'][i].copy())"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKRRNm8rT14d"
      },
      "source": [
        "with open(\"finaloutputfile.json\", \"w\") as outfile:  \n",
        "    json.dump(train_data, outfile)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDfwcSe7Q-xE"
      },
      "source": [
        ""
      ],
      "execution_count": 124,
      "outputs": []
    }
  ]
}